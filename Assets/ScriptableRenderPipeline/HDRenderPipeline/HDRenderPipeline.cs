using System.Collections.Generic;
using UnityEngine.Rendering;
using System;
using System.Linq;
using UnityEngine.Experimental.PostProcessing;
using UnityEngine.Experimental.Rendering.HDPipeline.TilePass;

#if UNITY_EDITOR
using UnityEditor;
#endif

namespace UnityEngine.Experimental.Rendering.HDPipeline
{
    [Serializable]
    public class RenderingSettings
    {
        public bool useForwardRenderingOnly = false; // TODO: Currently there is no way to strip the extra forward shaders generated by the shaders compiler, so we can switch dynamically.
        public bool useDepthPrepass = false;

        // We have to fall back to forward-only rendering when scene view is using wireframe rendering mode --
        // as rendering everything in wireframe + deferred do not play well together
        public bool ShouldUseForwardRenderingOnly()
        {
            return useForwardRenderingOnly || GL.wireframe;
        }
    }

    public struct HDCamera
    {
        public Camera    camera;
        public Vector4   screenSize;
        public Matrix4x4 viewProjectionMatrix;
        public Matrix4x4 invViewProjectionMatrix;
        public Matrix4x4 invProjectionMatrix;
        public Vector4   invProjectionParam;
    }

    public class GBufferManager
    {
        public const int MaxGbuffer = 8;

        public void SetBufferDescription(int index, string stringId, RenderTextureFormat inFormat, RenderTextureReadWrite inSRGBWrite)
        {
            IDs[index] = Shader.PropertyToID(stringId);
            RTIDs[index] = new RenderTargetIdentifier(IDs[index]);
            formats[index] = inFormat;
            sRGBWrites[index] = inSRGBWrite;
        }

        public void InitGBuffers(int width, int height, CommandBuffer cmd)
        {
            for (int index = 0; index < gbufferCount; index++)
            {
                cmd.GetTemporaryRT(IDs[index], width, height, 0, FilterMode.Point, formats[index], sRGBWrites[index]);
            }
        }

        public RenderTargetIdentifier[] GetGBuffers()
        {
            var colorMRTs = new RenderTargetIdentifier[gbufferCount];
            for (int index = 0; index < gbufferCount; index++)
            {
                colorMRTs[index] = RTIDs[index];
            }

            return colorMRTs;
        }

        public int gbufferCount { get; set; }
        int[] IDs = new int[MaxGbuffer];
        RenderTargetIdentifier[] RTIDs = new RenderTargetIdentifier[MaxGbuffer];
        RenderTextureFormat[] formats = new RenderTextureFormat[MaxGbuffer];
        RenderTextureReadWrite[] sRGBWrites = new RenderTextureReadWrite[MaxGbuffer];
    }

    public class HDRenderPipeline : RenderPipeline
    {
        readonly HDRenderPipelineAsset m_Asset;

        readonly RenderPipelineMaterial m_DeferredMaterial;
        readonly List<RenderPipelineMaterial> m_MaterialList = new List<RenderPipelineMaterial>();

        readonly GBufferManager m_gbufferManager = new GBufferManager();

        // Various set of material use in render loop
        Material m_FilterAndCombineSubsurfaceScattering;
        // Old SSS Model >>>
        Material m_FilterSubsurfaceScattering;
        // <<< Old SSS Model

        Material m_DebugViewMaterialGBuffer;
        Material m_DebugDisplayLatlong;
        Material m_DebugFullScreen;

        // Various buffer
        readonly int m_CameraColorBuffer;
        readonly int m_CameraSubsurfaceBuffer;
        // Old SSS Model >>>
        readonly int m_CameraFilteringBuffer;
        // <<< Old SSS Model
        readonly int m_VelocityBuffer;
        readonly int m_DistortionBuffer;

        // 'm_CameraColorBuffer' does not contain diffuse lighting of SSS materials until the SSS pass.
        // It is stored within 'm_CameraSubsurfaceBufferRT'.
        readonly RenderTargetIdentifier m_CameraColorBufferRT;
        readonly RenderTargetIdentifier m_CameraSubsurfaceBufferRT;
        // Old SSS Model >>>
        readonly RenderTargetIdentifier m_CameraFilteringBufferRT;
        // <<< Old SSS Model
        readonly RenderTargetIdentifier m_VelocityBufferRT;
        readonly RenderTargetIdentifier m_DistortionBufferRT;

        private RenderTexture m_CameraDepthStencilBuffer = null;
        private RenderTexture m_CameraDepthStencilBufferCopy = null;
        private RenderTargetIdentifier m_CameraDepthStencilBufferRT;
        private RenderTargetIdentifier m_CameraDepthStencilBufferCopyRT;

        // Post-processing context and screen-space effects (recycled on every frame to avoid GC alloc)
        readonly PostProcessRenderContext m_PostProcessContext;
        readonly ScreenSpaceAmbientOcclusionEffect m_SsaoEffect;

        // Stencil usage in HDRenderPipeline.
        // Currently we use only 2 bits to identify the kind of lighting that is expected from the render pipeline
        // Usage is define in LightDefinitions.cs
        [Flags]
        public enum StencilBits
        {
            Lighting = 3,                    // 0
            All = 255                        // 0xFF
        }

        // Detect when windows size is changing
        int m_CurrentWidth;
        int m_CurrentHeight;

        public int GetCurrentShadowCount() { return m_LightLoop.GetCurrentShadowCount(); }
        public int GetShadowAtlasCount() { return m_LightLoop.GetShadowAtlasCount(); }

        readonly SkyManager m_SkyManager = new SkyManager();
        readonly LightLoop m_LightLoop = new LightLoop();
        readonly ShadowSettings m_ShadowSettings = new ShadowSettings();

        // Debugging
        public DebugDisplaySettings m_DebugDisplaySettings = new DebugDisplaySettings();
        private int m_DebugFullScreenTempRT;
        private bool m_FullScreenDebugPushed = false;

        public SubsurfaceScatteringSettings sssSettings
        {
            get { return m_Asset.sssSettings; }
        }


        private CommonSettings.Settings m_CommonSettings = CommonSettings.Settings.s_Defaultsettings;
        private SkySettings m_SkySettings = null;
        private ScreenSpaceAmbientOcclusionSettings.Settings m_SsaoSettings = ScreenSpaceAmbientOcclusionSettings.Settings.s_Defaultsettings;

        public CommonSettings.Settings commonSettingsToUse
        {
            get
            {
                if (CommonSettingsSingleton.overrideSettings)
                    return CommonSettingsSingleton.overrideSettings.settings;

                return m_CommonSettings;
            }
        }

        public SkySettings skySettingsToUse
        {
            get
            {
                if (SkySettingsSingleton.overrideSettings)
                    return SkySettingsSingleton.overrideSettings;

                return m_SkySettings;
            }
        }

        public ScreenSpaceAmbientOcclusionSettings.Settings ssaoSettingsToUse
        {
            get
            {
                if (ScreenSpaceAmbientOcclusionSettingsSingleton.overrideSettings)
                    return ScreenSpaceAmbientOcclusionSettingsSingleton.overrideSettings.settings;

                return m_SsaoSettings;
            }
        }

        public HDRenderPipeline(HDRenderPipelineAsset asset)
        {
            m_Asset = asset;

            // Scan material list and assign it
            m_MaterialList = Utilities.GetRenderPipelineMaterialList();
            // Find first material that have non 0 Gbuffer count and assign it as deferredMaterial
            m_DeferredMaterial = null;
            foreach (RenderPipelineMaterial material in m_MaterialList)
            {
                if (material.GetMaterialGBufferCount() > 0)
                {
                    m_DeferredMaterial = material;
                }
            }

            // TODO: Handle the case of no Gbuffer material
            // TODO: I comment the assert here because m_DeferredMaterial for whatever reasons contain the correct class but with a "null" in the name instead of the real name and then trigger the assert
            // whereas it work. Don't know what is hapening, DebugDisplay use the same code and name is correct there.
            // Debug.Assert(m_DeferredMaterial != null);

            m_CameraColorBuffer             = Shader.PropertyToID("_CameraColorTexture");
            m_CameraSubsurfaceBuffer        = Shader.PropertyToID("_CameraSubsurfaceTexture");

            m_CameraColorBufferRT      = new RenderTargetIdentifier(m_CameraColorBuffer);
            m_CameraSubsurfaceBufferRT = new RenderTargetIdentifier(m_CameraSubsurfaceBuffer);

            // Old SSS Model >>>
            m_CameraFilteringBuffer   = Shader.PropertyToID("_CameraFilteringBuffer");
            m_CameraFilteringBufferRT = new RenderTargetIdentifier(m_CameraFilteringBuffer);
            CreateSssMaterials(sssSettings.useDisneySSS);
            // <<< Old SSS Model

            InitializeDebugMaterials();

            // Init Gbuffer description
            m_gbufferManager.gbufferCount = m_DeferredMaterial.GetMaterialGBufferCount();
            RenderTextureFormat[] RTFormat;
            RenderTextureReadWrite[] RTReadWrite;
            m_DeferredMaterial.GetMaterialGBufferDescription(out RTFormat, out RTReadWrite);

            for (int gbufferIndex = 0; gbufferIndex < m_gbufferManager.gbufferCount; ++gbufferIndex)
            {
                m_gbufferManager.SetBufferDescription(gbufferIndex, "_GBufferTexture" + gbufferIndex, RTFormat[gbufferIndex], RTReadWrite[gbufferIndex]);
            }

            m_VelocityBuffer = Shader.PropertyToID("_VelocityTexture");
            if (ShaderConfig.s_VelocityInGbuffer == 1)
            {
                // If velocity is in GBuffer then it is in the last RT. Assign a different name to it.
                m_gbufferManager.SetBufferDescription(m_gbufferManager.gbufferCount, "_VelocityTexture", Builtin.GetVelocityBufferFormat(), Builtin.GetVelocityBufferReadWrite());
                m_gbufferManager.gbufferCount++;
            }
            m_VelocityBufferRT = new RenderTargetIdentifier(m_VelocityBuffer);

            m_DistortionBuffer = Shader.PropertyToID("_DistortionTexture");
            m_DistortionBufferRT = new RenderTargetIdentifier(m_DistortionBuffer);

            m_MaterialList.ForEach(material => material.Build(asset.renderPipelineResources));

            m_LightLoop.Build(asset.renderPipelineResources, asset.tileSettings, asset.textureSettings, asset.shadowInitParams, m_ShadowSettings);

            m_SkyManager.Build(asset.renderPipelineResources);
            m_SkyManager.skySettings = skySettingsToUse;

            m_PostProcessContext = new PostProcessRenderContext();
            m_SsaoEffect = new ScreenSpaceAmbientOcclusionEffect();
            m_SsaoEffect.Build(asset.renderPipelineResources);

            m_DebugDisplaySettings.RegisterDebug();
            m_DebugFullScreenTempRT = Shader.PropertyToID("_DebugFullScreenTexture");
        }

        void InitializeDebugMaterials()
        {
            m_DebugViewMaterialGBuffer = Utilities.CreateEngineMaterial(m_Asset.renderPipelineResources.debugViewMaterialGBufferShader);
            m_DebugDisplayLatlong = Utilities.CreateEngineMaterial(m_Asset.renderPipelineResources.debugDisplayLatlongShader);
            m_DebugFullScreen = Utilities.CreateEngineMaterial(m_Asset.renderPipelineResources.debugFullScreenShader);
        }

        // Old SSS Model >>>
        public void CreateSssMaterials(bool useDisneySSS)
        {
            Utilities.Destroy(m_FilterSubsurfaceScattering);
            m_FilterSubsurfaceScattering = Utilities.CreateEngineMaterial("Hidden/HDRenderPipeline/CombineSubsurfaceScattering");
            Utilities.SelectKeyword(m_FilterSubsurfaceScattering, "SSS_MODEL_DISNEY", "SSS_MODEL_BASIC", useDisneySSS);
            m_FilterSubsurfaceScattering.DisableKeyword("SSS_FILTER_HORIZONTAL_AND_COMBINE");
            m_FilterSubsurfaceScattering.SetFloat("_DstBlend", (float)BlendMode.Zero);

            Utilities.Destroy(m_FilterAndCombineSubsurfaceScattering);
            m_FilterAndCombineSubsurfaceScattering = Utilities.CreateEngineMaterial("Hidden/HDRenderPipeline/CombineSubsurfaceScattering");
            Utilities.SelectKeyword(m_FilterAndCombineSubsurfaceScattering, "SSS_MODEL_DISNEY", "SSS_MODEL_BASIC", useDisneySSS);
            m_FilterAndCombineSubsurfaceScattering.EnableKeyword("SSS_FILTER_HORIZONTAL_AND_COMBINE");
            m_FilterAndCombineSubsurfaceScattering.SetFloat("_DstBlend", (float)BlendMode.One);
        }
        // <<< Old SSS Model

        public void OnSceneLoad()
        {
            // Recreate the textures which went NULL
            m_MaterialList.ForEach(material => material.Build(m_Asset.renderPipelineResources));
        }

        public override void Dispose()
        {
            base.Dispose();

            m_LightLoop.Cleanup();

            m_MaterialList.ForEach(material => material.Cleanup());

            Utilities.Destroy(m_DebugViewMaterialGBuffer);
            Utilities.Destroy(m_DebugDisplayLatlong);

            m_SkyManager.Cleanup();

            m_SsaoEffect.Cleanup();

#if UNITY_EDITOR
            SupportedRenderingFeatures.active = SupportedRenderingFeatures.Default;
#endif
        }

#if UNITY_EDITOR
        private static readonly SupportedRenderingFeatures s_NeededFeatures = new SupportedRenderingFeatures()
        {
            reflectionProbe = SupportedRenderingFeatures.ReflectionProbe.Rotation
        };
#endif

        void CreateDepthBuffer(Camera camera)
        {
            if (m_CameraDepthStencilBuffer != null)
            {
                m_CameraDepthStencilBuffer.Release();
            }

            m_CameraDepthStencilBuffer = new RenderTexture(camera.pixelWidth, camera.pixelHeight, 24, RenderTextureFormat.Depth);
            m_CameraDepthStencilBuffer.filterMode = FilterMode.Point;
            m_CameraDepthStencilBuffer.Create();
            m_CameraDepthStencilBufferRT = new RenderTargetIdentifier(m_CameraDepthStencilBuffer);

            if (NeedDepthBufferCopy())
            {
                if (m_CameraDepthStencilBufferCopy != null)
                {
                    m_CameraDepthStencilBufferCopy.Release();
                }
                m_CameraDepthStencilBufferCopy = new RenderTexture(camera.pixelWidth, camera.pixelHeight, 24, RenderTextureFormat.Depth);
                m_CameraDepthStencilBufferCopy.filterMode = FilterMode.Point;
                m_CameraDepthStencilBufferCopy.Create();
                m_CameraDepthStencilBufferCopyRT = new RenderTargetIdentifier(m_CameraDepthStencilBufferCopy);
            }
        }

        void Resize(Camera camera)
        {
            // TODO: Detect if renderdoc just load and force a resize in this case, as often renderdoc require to realloc resource.

            // TODO: This is the wrong way to handle resize/allocation. We can have several different camera here, mean that the loop on camera will allocate and deallocate
            // the below buffer which is bad. Best is to have a set of buffer for each camera that is persistent and reallocate resource if need
            // For now consider we have only one camera that go to this code, the main one.
            m_SkyManager.skySettings = skySettingsToUse;
            m_SkyManager.Resize(camera.nearClipPlane, camera.farClipPlane); // TODO: Also a bad naming, here we just want to realloc texture if skyparameters change (useful for lookdev)

            bool resolutionChanged = camera.pixelWidth != m_CurrentWidth || camera.pixelHeight != m_CurrentHeight;

            if (resolutionChanged || m_CameraDepthStencilBuffer == null)
            {
                CreateDepthBuffer(camera);
            }

            if (resolutionChanged || m_LightLoop.NeedResize())
            {
                if (m_CurrentWidth > 0 && m_CurrentHeight > 0)
                {
                    m_LightLoop.ReleaseResolutionDependentBuffers();
                }

                m_LightLoop.AllocResolutionDependentBuffers(camera.pixelWidth, camera.pixelHeight);
            }

            // update recorded window resolution
            m_CurrentWidth = camera.pixelWidth;
            m_CurrentHeight = camera.pixelHeight;
        }

        public void PushGlobalParams(HDCamera hdCamera, ScriptableRenderContext renderContext, SubsurfaceScatteringSettings sssParameters)
        {
            var cmd = new CommandBuffer {name = "Push Global Parameters"};

            cmd.SetGlobalVector("_ScreenSize",        hdCamera.screenSize);
            cmd.SetGlobalMatrix("_ViewProjMatrix",    hdCamera.viewProjectionMatrix);
            cmd.SetGlobalMatrix("_InvViewProjMatrix", hdCamera.invViewProjectionMatrix);
            cmd.SetGlobalMatrix("_InvProjMatrix",     hdCamera.invProjectionMatrix);
            cmd.SetGlobalVector("_InvProjParam",      hdCamera.invProjectionParam);

            // TODO: cmd.SetGlobalInt() does not exist, so we are forced to use Shader.SetGlobalInt() instead.

            if (m_SkyManager.IsSkyValid())
            {
                m_SkyManager.SetGlobalSkyTexture();
                Shader.SetGlobalInt("_EnvLightSkyEnabled", 1);
            }
            else
            {
                Shader.SetGlobalInt("_EnvLightSkyEnabled", 0);
            }

            // Broadcast SSS parameters to all shaders.
            Shader.SetGlobalInt(     "_EnableSSSAndTransmission",          m_DebugDisplaySettings.renderingDebugSettings.enableSSSAndTransmission ? 1 : 0);
            Shader.SetGlobalInt(     "_TexturingModeFlags", (int)sssParameters.texturingModeFlags);
            Shader.SetGlobalInt(     "_TransmissionFlags",  (int)sssParameters.transmissionFlags);
            cmd.SetGlobalFloatArray( "_ThicknessRemaps",         sssParameters.thicknessRemaps);
            cmd.SetGlobalVectorArray("_ShapeParams",             sssParameters.shapeParams);
            cmd.SetGlobalVectorArray("_TransmissionTints",       sssParameters.transmissionTints);

            renderContext.ExecuteCommandBuffer(cmd);
            cmd.Dispose();
        }

        bool NeedDepthBufferCopy()
        {
            // For now we consider only PS4 to be able to read from a bound depth buffer. Need to test/implement for other platforms.
            return SystemInfo.graphicsDeviceType != GraphicsDeviceType.PlayStation4;
        }

        Texture GetDepthTexture()
        {
            if (NeedDepthBufferCopy())
                return m_CameraDepthStencilBufferCopy;
            else
                return m_CameraDepthStencilBuffer;
        }

        private void CopyDepthBufferIfNeeded(ScriptableRenderContext renderContext)
        {
            var cmd = new CommandBuffer() { name = NeedDepthBufferCopy() ? "Copy DepthBuffer" : "Set DepthBuffer"};

            if (NeedDepthBufferCopy())
            {
                using (new Utilities.ProfilingSample("Copy depth-stencil buffer", renderContext))
                {
                    cmd.CopyTexture(m_CameraDepthStencilBufferRT, m_CameraDepthStencilBufferCopyRT);
                }
            }

            cmd.SetGlobalTexture("_MainDepthTexture", GetDepthTexture());
            renderContext.ExecuteCommandBuffer(cmd);
            cmd.Dispose();
        }

        public void UpdateCommonSettings()
        {
            var commonSettings = commonSettingsToUse;

            m_ShadowSettings.maxShadowDistance = commonSettings.shadowMaxDistance;
            m_ShadowSettings.directionalLightNearPlaneOffset = commonSettings.shadowNearPlaneOffset;
        }

        public override void Render(ScriptableRenderContext renderContext, Camera[] cameras)
        {
            base.Render(renderContext, cameras);

#if UNITY_EDITOR
            SupportedRenderingFeatures.active = s_NeededFeatures;
#endif

            GraphicsSettings.lightsUseLinearIntensity = true;
            GraphicsSettings.lightsUseColorTemperature = true;

            m_MaterialList.ForEach(material => material.RenderInit(renderContext));

            // Do anything we need to do upon a new frame.
            m_LightLoop.NewFrame();

            ApplyDebugDisplaySettings();
            UpdateCommonSettings();

            // Set Frame constant buffer
            // TODO...

            // we only want to render one camera for now
            // select the most main camera!

            Camera camera = cameras.OrderByDescending(x => x.tag == "MainCamera").FirstOrDefault();
            if (camera == null)
            {
                renderContext.Submit();
                return;
            }

            // Set camera constant buffer
            // TODO...

            ScriptableCullingParameters cullingParams;
            if (!CullResults.GetCullingParameters(camera, out cullingParams))
            {
                renderContext.Submit();
                return;
            }

            m_LightLoop.UpdateCullingParameters( ref cullingParams );

            var cullResults = CullResults.Cull(ref cullingParams, renderContext);

            Resize(camera);

            renderContext.SetupCameraProperties(camera);

            HDCamera hdCamera = Utilities.GetHDCamera(camera);

            // TODO: Find a correct place to bind these material textures
            // We have to bind the material specific global parameters in this mode
            m_MaterialList.ForEach(material => material.Bind());

            InitAndClearBuffer(camera, renderContext);

            PushGlobalParams(hdCamera, renderContext, m_Asset.sssSettings);

            RenderDepthPrepass(cullResults, camera, renderContext);

            // Forward opaque with deferred/cluster tile require that we fill the depth buffer
            // correctly to build the light list.
            RenderForwardOnlyOpaqueDepthPrepass(cullResults, camera, renderContext);
            RenderGBuffer(cullResults, camera, renderContext);

            // If full forward rendering, we did not do any rendering yet, so don't need to copy the buffer.
            // If Deferred then the depth buffer is full (regular GBuffer + ForwardOnly depth prepass are done so we can copy it safely.
            if (!m_Asset.renderingSettings.useForwardRenderingOnly)
            {
                CopyDepthBufferIfNeeded(renderContext);
            }

            if (m_DebugDisplaySettings.IsDebugMaterialDisplayEnabled())
            {
                RenderDebugViewMaterial(cullResults, hdCamera, renderContext);
            }
            else
            {
                using (new Utilities.ProfilingSample("Build Light list and render shadows", renderContext))
                {
                    // TODO: Everything here (SSAO, Shadow, Build light list, material and light classification can be parallelize with Async compute)
                    m_SsaoEffect.Render(ssaoSettingsToUse, this, hdCamera, renderContext, m_Asset.renderingSettings.useForwardRenderingOnly);
                    m_LightLoop.PrepareLightsForGPU(m_ShadowSettings, cullResults, camera);
                    m_LightLoop.RenderShadows(renderContext, cullResults);
                    renderContext.SetupCameraProperties(camera); // Need to recall SetupCameraProperties after m_ShadowPass.Render
                    m_LightLoop.BuildGPULightLists(camera, renderContext, m_CameraDepthStencilBufferRT);
                }

                // Caution: We require sun light here as some sky use the sun light to render, mean UpdateSkyEnvironment
                // must be call after BuildGPULightLists.
                // TODO: Try to arrange code so we can trigger this call earlier and use async compute here to run sky convolution during other passes (once we move convolution shader to compute).
                UpdateSkyEnvironment(hdCamera, renderContext);

                RenderDeferredLighting(hdCamera, renderContext);

                // We compute subsurface scattering here. Therefore, no objects rendered afterwards will exhibit SSS.
                // Currently, there is no efficient way to switch between SRT and MRT for the forward pass;
                // therefore, forward-rendered objects do not output split lighting required for the SSS pass.
                CombineSubsurfaceScattering(hdCamera, renderContext, m_Asset.sssSettings);

                // For opaque forward we have split rendering in two categories
                // Material that are always forward and material that can be deferred or forward depends on render pipeline options (like switch to rendering forward only mode)
                // Material that are always forward are unlit and complex (Like Hair) and don't require sorting, so it is ok to split them.
                RenderForward(cullResults, camera, renderContext, true); // Render deferred or forward opaque
                RenderForwardOnlyOpaque(cullResults, camera, renderContext);

                RenderLightingDebug(hdCamera, renderContext, m_CameraColorBufferRT);

                // If full forward rendering, we did just rendered everything, so we can copy the depth buffer
                // If Deferred nothing needs copying anymore.
                if (m_Asset.renderingSettings.useForwardRenderingOnly)
                {
                    CopyDepthBufferIfNeeded(renderContext);
                }

                RenderSky(hdCamera, renderContext);

                // Render all type of transparent forward (unlit, lit, complex (hair...)) to keep the sorting between transparent objects.
                RenderForward(cullResults, camera, renderContext, false);

                // Planar and real time cubemap doesn't need post process and render in FP16
                if (camera.cameraType == CameraType.Reflection)
                {
                    // Simple blit
                    var cmd = new CommandBuffer { name = "Blit to final RT" };
                    cmd.Blit(m_CameraColorBufferRT, BuiltinRenderTextureType.CameraTarget);
                    renderContext.ExecuteCommandBuffer(cmd);
                    cmd.Dispose();
                }
                else
                {
                    RenderVelocity(cullResults, camera, renderContext); // Note we may have to render velocity earlier if we do temporalAO, temporal volumetric etc... Mean we will not take into account forward opaque in case of deferred rendering ?

                    // TODO: Check with VFX team.
                    // Rendering distortion here have off course lot of artifact.
                    // But resolving at each objects that write in distortion is not possible (need to sort transparent, render those that do not distort, then resolve, then etc...)
                    // Instead we chose to apply distortion at the end after we cumulate distortion vector and desired blurriness. This
                    RenderDistortion(cullResults, camera, renderContext);

                    RenderPostProcesses(camera, renderContext);
                }
            }

            RenderDebug(hdCamera, renderContext);

            // bind depth surface for editor grid/gizmo/selection rendering
            if (camera.cameraType == CameraType.SceneView)
            {
                var cmd = new CommandBuffer();
                cmd.SetRenderTarget(BuiltinRenderTextureType.CameraTarget, m_CameraDepthStencilBufferRT);
                renderContext.ExecuteCommandBuffer(cmd);
                cmd.Dispose();
            }

            renderContext.Submit();
        }

        void RenderOpaqueRenderList(CullResults cull, Camera camera, ScriptableRenderContext renderContext, string passName, RendererConfiguration rendererConfiguration = 0)
        {
            if (!m_DebugDisplaySettings.renderingDebugSettings.displayOpaqueObjects)
                return;

            var settings = new DrawRendererSettings(cull, camera, new ShaderPassName(passName))
            {
                rendererConfiguration = rendererConfiguration,
                sorting = { flags = SortFlags.CommonOpaque }
            };
            settings.inputFilter.SetQueuesOpaque();
            renderContext.DrawRenderers(ref settings);
        }

        void RenderTransparentRenderList(CullResults cull, Camera camera, ScriptableRenderContext renderContext, string passName, RendererConfiguration rendererConfiguration = 0)
        {
            if (!m_DebugDisplaySettings.renderingDebugSettings.displayTransparentObjects)
                return;

            var settings = new DrawRendererSettings(cull, camera, new ShaderPassName(passName))
            {
                rendererConfiguration = rendererConfiguration,
                sorting = { flags = SortFlags.CommonTransparent }
            };
            settings.inputFilter.SetQueuesTransparent();
            renderContext.DrawRenderers(ref settings);
        }

        void RenderDepthPrepass(CullResults cull, Camera camera, ScriptableRenderContext renderContext)
        {
            // If we are forward only we will do a depth prepass
            // TODO: Depth prepass should be enabled based on light loop settings. LightLoop define if they need a depth prepass + forward only...
            if (!m_Asset.renderingSettings.useDepthPrepass)
                return;

            using (new Utilities.ProfilingSample("Depth Prepass", renderContext))
            {
                // TODO: Must do opaque then alpha masked for performance!
                // TODO: front to back for opaque and by materal for opaque tested when we split in two
                Utilities.SetRenderTarget(renderContext, m_CameraDepthStencilBufferRT);
                RenderOpaqueRenderList(cull, camera, renderContext, "DepthOnly");
            }
        }

        void RenderGBuffer(CullResults cull, Camera camera, ScriptableRenderContext renderContext)
        {
            if (m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
            {
                return;
            }

            string passName = m_DebugDisplaySettings.IsDebugDisplayEnabled() ? "GBufferDebugDisplay" : "GBuffer";

            using (new Utilities.ProfilingSample(passName, renderContext))
            {
                // setup GBuffer for rendering
                Utilities.SetRenderTarget(renderContext, m_gbufferManager.GetGBuffers(), m_CameraDepthStencilBufferRT);
                // render opaque objects into GBuffer
                RenderOpaqueRenderList(cull, camera, renderContext, passName, Utilities.kRendererConfigurationBakedLighting);
            }
        }

        // This pass is use in case of forward opaque and deferred rendering. We need to render forward objects before tile lighting pass
        void RenderForwardOnlyOpaqueDepthPrepass(CullResults cull, Camera camera, ScriptableRenderContext renderContext)
        {
            // If we are forward only we don't need to render ForwardOnlyOpaqueDepthOnly object
            // But in case we request a prepass we render it
            if (m_Asset.renderingSettings.ShouldUseForwardRenderingOnly() && !m_Asset.renderingSettings.useDepthPrepass)
                return;

            using (new Utilities.ProfilingSample("Forward opaque depth", renderContext))
            {
                Utilities.SetRenderTarget(renderContext, m_CameraDepthStencilBufferRT);
                RenderOpaqueRenderList(cull, camera, renderContext, "ForwardOnlyOpaqueDepthOnly");
            }
        }

        void RenderDebugViewMaterial(CullResults cull, HDCamera hdCamera, ScriptableRenderContext renderContext)
        {
            using (new Utilities.ProfilingSample("DisplayDebug ViewMaterial", renderContext))
            {
                // Render Opaque forward
                Utilities.SetRenderTarget(renderContext, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT, Utilities.kClearAll, Color.black);
                RenderOpaqueRenderList(cull, hdCamera.camera, renderContext, "ForwardDisplayDebug", Utilities.kRendererConfigurationBakedLighting);

                // Render GBuffer opaque
                if (!m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
                {
                    Utilities.SetupMaterialHDCamera(hdCamera, m_DebugViewMaterialGBuffer);

                    // TODO: Bind depth textures
                    var cmd = new CommandBuffer { name = "DebugViewMaterialGBuffer" };
                    cmd.Blit(null, m_CameraColorBufferRT, m_DebugViewMaterialGBuffer, 0);
                    renderContext.ExecuteCommandBuffer(cmd);
                    cmd.Dispose();
                }

                // Render forward transparent
                {
                    RenderTransparentRenderList(cull, hdCamera.camera, renderContext, "ForwardDisplayDebug", Utilities.kRendererConfigurationBakedLighting);
                }
            }

            // Last blit
            {
                var cmd = new CommandBuffer { name = "Blit DebugView Material Debug" };
                cmd.Blit(m_CameraColorBufferRT, BuiltinRenderTextureType.CameraTarget);
                renderContext.ExecuteCommandBuffer(cmd);
                cmd.Dispose();
            }
        }

        void RenderDeferredLighting(HDCamera hdCamera, ScriptableRenderContext renderContext)
        {
            if (m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
            {
                return;
            }

            RenderTargetIdentifier[] colorRTs = { m_CameraColorBufferRT, m_CameraSubsurfaceBufferRT };

            if (m_DebugDisplaySettings.renderingDebugSettings.enableSSSAndTransmission)
            {
                // Output split lighting for materials asking for it (via stencil buffer)
                m_LightLoop.RenderDeferredLighting(hdCamera, renderContext, m_DebugDisplaySettings, colorRTs, m_CameraDepthStencilBufferRT, new RenderTargetIdentifier(GetDepthTexture()), true);
            }

            // Output combined lighting for all the other materials.
            m_LightLoop.RenderDeferredLighting(hdCamera, renderContext, m_DebugDisplaySettings, colorRTs, m_CameraDepthStencilBufferRT, new RenderTargetIdentifier(GetDepthTexture()), false);
        }

        // Combines specular lighting and diffuse lighting with subsurface scattering.
        void CombineSubsurfaceScattering(HDCamera hdCamera, ScriptableRenderContext context, SubsurfaceScatteringSettings sssParameters)
        {
            // Currently, forward-rendered objects do not output split lighting required for the SSS pass.
            if (!m_DebugDisplaySettings.renderingDebugSettings.enableSSSAndTransmission || m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
                return;

            var cmd = new CommandBuffer() { name = "Subsurface Scattering" };

            if (sssSettings.useDisneySSS)
            {
                cmd.SetGlobalTexture("_IrradianceSource", m_CameraSubsurfaceBufferRT); // Cannot set a RT on a material
                m_FilterAndCombineSubsurfaceScattering.SetFloatArray("_WorldScales",            sssParameters.worldScales);
                m_FilterAndCombineSubsurfaceScattering.SetFloatArray("_FilterKernelsNearField", sssParameters.filterKernelsNearField);
                m_FilterAndCombineSubsurfaceScattering.SetFloatArray("_FilterKernelsFarField",  sssParameters.filterKernelsFarField);

                Utilities.DrawFullScreen(cmd, m_FilterAndCombineSubsurfaceScattering, hdCamera, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT);
            }
            else
            {
                // Perform the vertical SSS filtering pass.
                cmd.SetGlobalTexture("_IrradianceSource", m_CameraSubsurfaceBufferRT);  // Cannot set a RT on a material
                m_FilterSubsurfaceScattering.SetFloatArray("_WorldScales",               sssParameters.worldScales);
                m_FilterSubsurfaceScattering.SetVectorArray("_FilterKernelsBasic",       sssParameters.filterKernelsBasic);
                m_FilterSubsurfaceScattering.SetVectorArray("_HalfRcpWeightedVariances", sssParameters.halfRcpWeightedVariances);
                Utilities.DrawFullScreen(cmd, m_FilterSubsurfaceScattering, hdCamera, m_CameraFilteringBufferRT, m_CameraDepthStencilBufferRT);

                // Perform the horizontal SSS filtering pass, and combine diffuse and specular lighting.
                cmd.SetGlobalTexture("_IrradianceSource", m_CameraFilteringBufferRT);  // Cannot set a RT on a material
                m_FilterAndCombineSubsurfaceScattering.SetFloatArray("_WorldScales",               sssParameters.worldScales);
                m_FilterAndCombineSubsurfaceScattering.SetVectorArray("_FilterKernelsBasic",       sssParameters.filterKernelsBasic);
                m_FilterAndCombineSubsurfaceScattering.SetVectorArray("_HalfRcpWeightedVariances", sssParameters.halfRcpWeightedVariances);
                Utilities.DrawFullScreen(cmd, m_FilterAndCombineSubsurfaceScattering, hdCamera, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT);
            }

            context.ExecuteCommandBuffer(cmd);
            cmd.Dispose();
        }

        void UpdateSkyEnvironment(HDCamera hdCamera, ScriptableRenderContext renderContext)
        {
            m_SkyManager.UpdateEnvironment(hdCamera,m_LightLoop.GetCurrentSunLight(), renderContext);
        }

        void RenderSky(HDCamera hdCamera, ScriptableRenderContext renderContext)
        {
            m_SkyManager.RenderSky(hdCamera, m_LightLoop.GetCurrentSunLight(), m_CameraColorBufferRT, m_CameraDepthStencilBufferRT, renderContext);
        }

        public Texture2D ExportSkyToTexture()
        {
            return m_SkyManager.ExportSkyToTexture();
        }

        void RenderLightingDebug(HDCamera camera, ScriptableRenderContext renderContext, RenderTargetIdentifier colorBuffer)
        {
            m_LightLoop.RenderLightingDebug(camera, renderContext, colorBuffer);
        }

        void RenderForward(CullResults cullResults, Camera camera, ScriptableRenderContext renderContext, bool renderOpaque)
        {
            // TODO: Currently we can't render opaque object forward when deferred is enabled
            // miss option
            if (!m_Asset.renderingSettings.ShouldUseForwardRenderingOnly() && renderOpaque)
                return;

            string passName = m_DebugDisplaySettings.IsDebugDisplayEnabled() ? "ForwardDisplayDebug" : "Forward";

            using (new Utilities.ProfilingSample(passName, renderContext))
            {
                Utilities.SetRenderTarget(renderContext, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT);

                m_LightLoop.RenderForward(camera, renderContext, renderOpaque);

                if (renderOpaque)
                {
                    RenderOpaqueRenderList(cullResults, camera, renderContext, passName, Utilities.kRendererConfigurationBakedLighting);
                }
                else
                {
                    RenderTransparentRenderList(cullResults, camera, renderContext, passName, Utilities.kRendererConfigurationBakedLighting);
                }
            }
        }

        // Render material that are forward opaque only (like eye), this include unlit material
        void RenderForwardOnlyOpaque(CullResults cullResults, Camera camera, ScriptableRenderContext renderContext)
        {
            string passName = m_DebugDisplaySettings.IsDebugDisplayEnabled() ? "ForwardOnlyOpaqueDisplayDebug" : "ForwardOnlyOpaque";

            using (new Utilities.ProfilingSample(passName, renderContext))
            {
                Utilities.SetRenderTarget(renderContext, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT);

                m_LightLoop.RenderForward(camera, renderContext, true);

                RenderOpaqueRenderList(cullResults, camera, renderContext, passName, Utilities.kRendererConfigurationBakedLighting);
            }
        }

        void RenderVelocity(CullResults cullResults, Camera camera, ScriptableRenderContext renderContext)
        {
            using (new Utilities.ProfilingSample("Velocity", renderContext))
            {
                // If opaque velocity have been render during GBuffer no need to render it here
                if ((ShaderConfig.s_VelocityInGbuffer == 1) || m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
                    return;

                int w = camera.pixelWidth;
                int h = camera.pixelHeight;

                var cmd = new CommandBuffer { name = "" };
                cmd.GetTemporaryRT(m_VelocityBuffer, w, h, 0, FilterMode.Point, Builtin.GetVelocityBufferFormat(), Builtin.GetVelocityBufferReadWrite());
                cmd.SetRenderTarget(m_VelocityBufferRT, m_CameraDepthStencilBufferRT);
                renderContext.ExecuteCommandBuffer(cmd);
                cmd.Dispose();

                RenderOpaqueRenderList(cullResults, camera, renderContext, "MotionVectors");
            }
        }

        void RenderDistortion(CullResults cullResults, Camera camera, ScriptableRenderContext renderContext)
        {
            if (!m_DebugDisplaySettings.renderingDebugSettings.enableDistortion)
                return;

            using (new Utilities.ProfilingSample("Distortion", renderContext))
            {
                int w = camera.pixelWidth;
                int h = camera.pixelHeight;

                var cmd = new CommandBuffer { name = "" };
                cmd.GetTemporaryRT(m_DistortionBuffer, w, h, 0, FilterMode.Point, Builtin.GetDistortionBufferFormat(), Builtin.GetDistortionBufferReadWrite());
                cmd.SetRenderTarget(m_DistortionBufferRT, m_CameraDepthStencilBufferRT);
                cmd.ClearRenderTarget(false, true, Color.black); // TODO: can we avoid this clear for performance ?
                renderContext.ExecuteCommandBuffer(cmd);
                cmd.Dispose();

                // Only transparent object can render distortion vectors
                RenderTransparentRenderList(cullResults, camera, renderContext, "DistortionVectors");
            }
        }

        void RenderPostProcesses(Camera camera, ScriptableRenderContext renderContext)
        {
            using (new Utilities.ProfilingSample("Post-processing", renderContext))
            {
                var postProcessLayer = camera.GetComponent<PostProcessLayer>();
                var cmd = new CommandBuffer { name = "" };

                if (postProcessLayer != null && postProcessLayer.enabled)
                {
                    cmd.SetGlobalTexture("_CameraDepthTexture", GetDepthTexture());

                    var context = m_PostProcessContext;
                    context.Reset();
                    context.source = m_CameraColorBufferRT;
                    context.destination = BuiltinRenderTextureType.CameraTarget;
                    context.command = cmd;
                    context.camera = camera;
                    context.sourceFormat = RenderTextureFormat.ARGBHalf; // ?
                    context.flip = true;

                    postProcessLayer.Render(context);
                }
                else
                {
                    cmd.Blit(m_CameraColorBufferRT, BuiltinRenderTextureType.CameraTarget);
                }

                renderContext.ExecuteCommandBuffer(cmd);
                cmd.Dispose();
            }
        }

        public void ApplyDebugDisplaySettings()
        {
            m_ShadowSettings.enabled = m_DebugDisplaySettings.lightingDebugSettings.enableShadows;

            LightingDebugSettings lightingDebugSettings = m_DebugDisplaySettings.lightingDebugSettings;
            Vector4 debugAlbedo = new Vector4(lightingDebugSettings.debugLightingAlbedo.r, lightingDebugSettings.debugLightingAlbedo.g, lightingDebugSettings.debugLightingAlbedo.b, 0.0f);
            Vector4 debugSmoothness = new Vector4(lightingDebugSettings.overrideSmoothness ? 1.0f : 0.0f, lightingDebugSettings.overrideSmoothnessValue, 0.0f, 0.0f);

            Shader.SetGlobalInt("_DebugViewMaterial", (int)m_DebugDisplaySettings.GetDebugMaterialIndex());
            Shader.SetGlobalInt("_DebugLightingMode", (int)m_DebugDisplaySettings.GetDebugLightingMode());
            Shader.SetGlobalVector("_DebugLightingAlbedo", debugAlbedo);
            Shader.SetGlobalVector("_DebugLightingSmoothness", debugSmoothness);
        }

        public void PushFullScreenDebugTexture(CommandBuffer cb, int textureID, Camera camera, ScriptableRenderContext renderContext, FullScreenDebugMode debugMode)
        {
            if(debugMode == m_DebugDisplaySettings.lightingDebugSettings.fullScreenDebugMode)
            {
                m_FullScreenDebugPushed = true; // We need this flag because otherwise if no fullscreen debug is pushed, when we render the result in RenderDebug the temporary RT will not exist.
                cb.GetTemporaryRT(m_DebugFullScreenTempRT, camera.pixelWidth, camera.pixelHeight, 0, FilterMode.Point, RenderTextureFormat.ARGBHalf, RenderTextureReadWrite.Linear);
                cb.Blit(textureID, m_DebugFullScreenTempRT);
            }
        }

        void RenderDebug(HDCamera camera, ScriptableRenderContext renderContext)
        {
            // We don't want any overlay for these kind of rendering
            if (camera.camera.cameraType == CameraType.Reflection || camera.camera.cameraType == CameraType.Preview)
                return;

            // We make sure the depth buffer is bound because we need it to write depth at near plane for overlays otherwise the editor grid end up visible in them.
            Utilities.SetRenderTarget(renderContext, BuiltinRenderTextureType.CameraTarget, m_CameraDepthStencilBufferRT);

            CommandBuffer debugCB = new CommandBuffer();
            debugCB.name = "Render Debug";

            // First render full screen debug texture
            if(m_DebugDisplaySettings.lightingDebugSettings.fullScreenDebugMode != FullScreenDebugMode.None && m_FullScreenDebugPushed)
            {
                m_FullScreenDebugPushed = false;
                debugCB.SetGlobalTexture("_DebugFullScreenTexture", m_DebugFullScreenTempRT);
                m_DebugFullScreen.SetFloat("_FullScreenDebugMode", (float)m_DebugDisplaySettings.lightingDebugSettings.fullScreenDebugMode);
                Utilities.DrawFullScreen(debugCB, m_DebugFullScreen, camera, BuiltinRenderTextureType.CameraTarget);
            }

            // Then overlays
            float x = 0;
            float overlayRatio = m_DebugDisplaySettings.debugOverlayRatio;
            float overlaySize = Math.Min(camera.camera.pixelHeight, camera.camera.pixelWidth) * overlayRatio;
            float y = camera.camera.pixelHeight - overlaySize;

            MaterialPropertyBlock propertyBlock = new MaterialPropertyBlock();

            LightingDebugSettings lightingDebug = m_DebugDisplaySettings.lightingDebugSettings;

            if (lightingDebug.displaySkyReflection)
            {
                Texture skyReflection = m_SkyManager.skyReflection;
                propertyBlock.SetTexture("_InputCubemap", skyReflection);
                propertyBlock.SetFloat("_Mipmap", lightingDebug.skyReflectionMipmap);
                debugCB.SetViewport(new Rect(x, y, overlaySize, overlaySize));
                debugCB.DrawProcedural(Matrix4x4.identity, m_DebugDisplayLatlong, 0, MeshTopology.Triangles, 3, 1, propertyBlock);
                Utilities.NextOverlayCoord(ref x, ref y, overlaySize, overlaySize, camera.camera.pixelWidth);
            }

            renderContext.ExecuteCommandBuffer(debugCB);

            m_LightLoop.RenderDebugOverlay(camera.camera, renderContext, m_DebugDisplaySettings, ref x, ref y, overlaySize, camera.camera.pixelWidth);
        }

        void InitAndClearBuffer(Camera camera, ScriptableRenderContext renderContext)
        {
            using (new Utilities.ProfilingSample("InitAndClearBuffer", renderContext))
            {
                // We clear only the depth buffer, no need to clear the various color buffer as we overwrite them.
                // Clear depth/stencil and init buffers
                using (new Utilities.ProfilingSample("InitGBuffers and clear Depth/Stencil", renderContext))
                {
                    var cmd = new CommandBuffer();
                    cmd.name = "";

                    // Init buffer
                    // With scriptable render loop we must allocate ourself depth and color buffer (We must be independent of backbuffer for now, hope to fix that later).
                    // Also we manage ourself the HDR format, here allocating fp16 directly.
                    // With scriptable render loop we can allocate temporary RT in a command buffer, they will not be release with ExecuteCommandBuffer
                    // These temporary surface are release automatically at the end of the scriptable render pipeline if not release explicitly
                    int w = camera.pixelWidth;
                    int h = camera.pixelHeight;

                    cmd.GetTemporaryRT(m_CameraColorBuffer,             w, h,  0, FilterMode.Point, RenderTextureFormat.ARGBHalf,       RenderTextureReadWrite.Linear, 1, true); // Enable UAV
                    cmd.GetTemporaryRT(m_CameraSubsurfaceBuffer,        w, h,  0, FilterMode.Point, RenderTextureFormat.RGB111110Float, RenderTextureReadWrite.Linear, 1, true); // Enable UAV
                    // Old SSS Model >>>
                    cmd.GetTemporaryRT(m_CameraFilteringBuffer,         w, h,  0, FilterMode.Point, RenderTextureFormat.RGB111110Float, RenderTextureReadWrite.Linear, 1, true); // Enable UAV
                    // <<< Old SSS Model

                    if (!m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
                    {
                        m_gbufferManager.InitGBuffers(w, h, cmd);
                    }

                    renderContext.ExecuteCommandBuffer(cmd);
                    cmd.Dispose();

                    Utilities.SetRenderTarget(renderContext, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT, ClearFlag.ClearDepth);
                }

                // Clear the diffuse SSS lighting target
                using (new Utilities.ProfilingSample("Clear SSS diffuse target", renderContext))
                {
                    Utilities.SetRenderTarget(renderContext, m_CameraSubsurfaceBufferRT, m_CameraDepthStencilBufferRT, ClearFlag.ClearColor, Color.black);
                }

                // Old SSS Model >>>
                // Clear the SSS filtering target
                using (new Utilities.ProfilingSample("Clear SSS filtering target", renderContext))
                {
                    Utilities.SetRenderTarget(renderContext, m_CameraFilteringBuffer, m_CameraDepthStencilBufferRT, ClearFlag.ClearColor, Color.black);
                }
                // <<< Old SSS Model

                // TEMP: As we are in development and have not all the setup pass we still clear the color in emissive buffer and gbuffer, but this will be removed later.

                // Clear the HDR target
                using (new Utilities.ProfilingSample("Clear HDR target", renderContext))
                {
                    Utilities.SetRenderTarget(renderContext, m_CameraColorBufferRT, m_CameraDepthStencilBufferRT, ClearFlag.ClearColor, Color.black);
                }

                // Clear GBuffers
                if (!m_Asset.renderingSettings.ShouldUseForwardRenderingOnly())
                {
                    using (new Utilities.ProfilingSample("Clear GBuffer", renderContext))
                    {
                        Utilities.SetRenderTarget(renderContext, m_gbufferManager.GetGBuffers(), m_CameraDepthStencilBufferRT, ClearFlag.ClearColor, Color.black);
                    }
                }
                // END TEMP
            }
        }
    }
}
